{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60f4d39-f43c-40c7-a094-fe7f640588c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--time_step TIME_STEP]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\B20770\\AppData\\Roaming\\jupyter\\runtime\\kernel-32efcc0b-ea0b-4dcd-ad03-610c2b7114b1.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\face\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.optim as optim\n",
    "from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, Live\n",
    "import pickle\n",
    "from Posture_ensemble_model import PostureLSTMModel, PostureGRUModel, PostureTemporalConvNet, PostureEnsembleModel\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "\n",
    "def main(time_step):\n",
    "    \"\"\"\n",
    "    主函數，用於訓練姿態集成模型。\n",
    "    \n",
    "    參數:\n",
    "    - time_step: int，滑動窗口的大小。\n",
    "    \n",
    "    功能:\n",
    "    - 加載數據並進行標籤編碼。\n",
    "    - 創建數據集和數據加載器。\n",
    "    - 初始化模型和訓練相關的參數。\n",
    "    - 訓練和評估模型。\n",
    "    - 保存訓練好的模型。\n",
    "    \"\"\"\n",
    "    # 加載數據\n",
    "    loaded = np.load('data_combined.npz')\n",
    "    data_slices = loaded['data']\n",
    "    labels = loaded['labels']\n",
    "\n",
    "    # 創建LabelEncoder並進行編碼\n",
    "    label_encoder = LabelEncoder()\n",
    "    int_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "    # 保存LabelEncoder到.pkl文件\n",
    "    with open('Model/posture_label_encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(label_encoder, f)\n",
    "\n",
    "    # 打印標籤列表\n",
    "    print(f'Labels: {label_encoder.classes_}')\n",
    "\n",
    "    # 創建數據集和數據加載器\n",
    "    class SkeletonDataset(Dataset):\n",
    "        \"\"\"\n",
    "        自定義數據集類別，用於加載骨架數據。\n",
    "        \n",
    "        參數:\n",
    "        - data: numpy.ndarray，數據片段。\n",
    "        - labels: numpy.ndarray，數據標籤。\n",
    "        \"\"\"\n",
    "        def __init__(self, data, labels):\n",
    "            self.data = data\n",
    "            self.labels = labels\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "    train_dataset = SkeletonDataset(data_slices, int_labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    # 設置參數\n",
    "    input_dim = 33 * 4  # 33 keypoints * 4 coords (xyzv)\n",
    "    hidden_dim = 128\n",
    "    num_layers = 2\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    tcn_channels = [128, 128]\n",
    "\n",
    "    lstm_model = PostureLSTMModel(input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, num_classes=num_classes)\n",
    "    gru_model = PostureGRUModel(input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, num_classes=num_classes)\n",
    "    tcn_model = PostureTemporalConvNet(num_inputs=input_dim, num_channels=tcn_channels, num_classes=num_classes, dropout=0.2)\n",
    "\n",
    "    # 創建集成模型\n",
    "    model = PostureEnsembleModel(lstm_model, gru_model, tcn_model, num_classes=num_classes)\n",
    "\n",
    "    # 將模型移動到GPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # 訓練函數\n",
    "    def train_model(model, train_loader, criterion, optimizer, num_epochs=20):\n",
    "        \"\"\"\n",
    "        訓練模型。\n",
    "        \n",
    "        參數:\n",
    "        - model: nn.Module，待訓練的模型。\n",
    "        - train_loader: DataLoader，訓練數據加載器。\n",
    "        - criterion: 損失函數。\n",
    "        - optimizer: 優化器。\n",
    "        - num_epochs: int，訓練的輪數。\n",
    "        \n",
    "        功能:\n",
    "        - 訓練模型並顯示訓練進度。\n",
    "        \"\"\"\n",
    "        progress = Progress(\n",
    "            SpinnerColumn(), \n",
    "            BarColumn(), \n",
    "            TextColumn(\"[progress.percentage]{task.percentage:>3.1f}%\"), \n",
    "            TextColumn(\"[progress.description]{task.description}\"),\n",
    "            auto_refresh=True\n",
    "        )\n",
    "\n",
    "        with Live(progress, refresh_per_second=10):\n",
    "            train_task = progress.add_task(\n",
    "                description=\"Initializing...\", \n",
    "                total=num_epochs * len(train_loader)\n",
    "            )\n",
    "            for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                running_loss = 0.0\n",
    "                \n",
    "                for inputs, labels in train_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    inputs = inputs.view(inputs.size(0), time_step, -1)  # 形狀為 (batch_size, frames, keypoints * coords)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "                    progress.update(\n",
    "                        train_task,\n",
    "                        description=f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\",\n",
    "                        advance=1\n",
    "                    )\n",
    "\n",
    "    # 評估函數\n",
    "    def evaluate_model(model, test_file_path):\n",
    "        \"\"\"\n",
    "        評估模型。\n",
    "        \n",
    "        參數:\n",
    "        - model: nn.Module，待評估的模型。\n",
    "        - test_file_path: str，測試數據的文件路徑。\n",
    "        \n",
    "        功能:\n",
    "        - 評估模型並顯示評估進度。\n",
    "        - 計算每一個動作的正確率。\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        action_correct = {}\n",
    "        action_total = {}\n",
    "\n",
    "        progress = Progress(\n",
    "            SpinnerColumn(), \n",
    "            BarColumn(), \n",
    "            TextColumn(\"[progress.percentage]{task.percentage:>3.1f}%\"), \n",
    "            TextColumn(\"[progress.description]{task.description}\"),\n",
    "            auto_refresh=True\n",
    "        )\n",
    "        \n",
    "        # 加載測試數據\n",
    "        loaded_test = np.load(test_file_path)\n",
    "        test_data_slices = loaded_test['data']\n",
    "        test_labels = loaded_test['labels']\n",
    "\n",
    "        # 創建測試數據集和數據加載器\n",
    "        test_dataset = SkeletonDataset(test_data_slices, label_encoder.transform(test_labels))\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        with Live(progress, refresh_per_second=10):\n",
    "            eval_task = progress.add_task(\"Evaluating\", total=len(test_loader))\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in test_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    inputs = inputs.view(1, time_step, -1)\n",
    "                    outputs = model(inputs)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    action = label_encoder.inverse_transform([labels.item()])[0]\n",
    "\n",
    "                    total_samples += 1\n",
    "                    if action not in action_total:\n",
    "                        action_total[action] = 0\n",
    "                        action_correct[action] = 0\n",
    "                    action_total[action] += 1\n",
    "                    if predicted.item() == labels.item():\n",
    "                        total_correct += 1\n",
    "                        action_correct[action] += 1\n",
    "\n",
    "                    progress.update(eval_task, advance=1)\n",
    "\n",
    "        overall_accuracy = 100 * total_correct / total_samples\n",
    "        print(f'Overall Accuracy of the model on the test set: {overall_accuracy:.2f}%')\n",
    "\n",
    "        for action in action_correct:\n",
    "            action_accuracy = 100 * action_correct[action] / action_total[action]\n",
    "            print(f'Accuracy for action {action}: {action_accuracy:.2f}%')\n",
    "\n",
    "    # 訓練模型\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs=128)\n",
    "\n",
    "    # 評估模型\n",
    "    evaluate_model(model, 'test_data.npz')\n",
    "\n",
    "    # 保存模型\n",
    "    torch.save({\n",
    "        'lstm_model_state_dict': lstm_model.state_dict(),\n",
    "        'gru_model_state_dict': gru_model.state_dict(),\n",
    "        'tcn_model_state_dict': tcn_model.state_dict(),\n",
    "        'ensemble_model_state_dict': model.state_dict()\n",
    "    }, r\"Model/Posture_ensemble_model.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Train the Posture Ensemble Model.\")\n",
    "    parser.add_argument(\"--time_step\", type=int, default=70, help=\"The size of the time step for the sliding window.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args.time_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b106329b-3032-4822-9100-997bcda4f6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee18490ae84448fab32dde880a23cf23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['Bent_Leg_Kickback' 'Bent_Over_Row' 'Bird_Dog' 'Crunch_Floor' 'Dead_Bug'\n",
      " 'Deadlift' 'Farmers_walk' 'Front_Plank' 'Kettlebell_Strict_Press'\n",
      " 'Mountain_Climber' 'Prone' 'Resistance_Band_Side_Walk' 'Russian_Twist'\n",
      " 'Squat' 'glute-bridge' 'push_up']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5d2f0dc0a64f67b10b3ef8a4b608c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of the model on the test set: 67.53%\n",
      "Accuracy for action Bent_Leg_Kickback: 90.57%\n",
      "Accuracy for action Bent_Over_Row: 11.76%\n",
      "Accuracy for action Bird_Dog: 52.45%\n",
      "Accuracy for action Crunch_Floor: 75.76%\n",
      "Accuracy for action Deadlift: 72.34%\n",
      "Accuracy for action Dead_Bug: 100.00%\n",
      "Accuracy for action Farmers_walk: 100.00%\n",
      "Accuracy for action Front_Plank: 100.00%\n",
      "Accuracy for action glute-bridge: 100.00%\n",
      "Accuracy for action Kettlebell_Strict_Press: 100.00%\n",
      "Accuracy for action Mountain_Climber: 0.00%\n",
      "Accuracy for action Prone: 0.00%\n",
      "Accuracy for action push_up: 100.00%\n",
      "Accuracy for action Resistance_Band_Side_Walk: 85.71%\n",
      "Accuracy for action Russian_Twist: 100.00%\n",
      "Accuracy for action Squat: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.optim as optim\n",
    "from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, Live\n",
    "import pickle\n",
    "from Posture_ensemble_model import PostureLSTMModel, PostureGRUModel, PostureTemporalConvNet, PostureEnsembleModel\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "def main(time_step):\n",
    "    \"\"\"\n",
    "    主函數，用於訓練姿態集成模型。\n",
    "    \n",
    "    參數:\n",
    "    - time_step: int，滑動窗口的大小。\n",
    "    \n",
    "    功能:\n",
    "    - 加載數據並進行標籤編碼。\n",
    "    - 創建數據集和數據加載器。\n",
    "    - 初始化模型和訓練相關的參數。\n",
    "    - 訓練和評估模型。\n",
    "    - 保存訓練好的模型。\n",
    "    \"\"\"\n",
    "    # 加載數據\n",
    "    loaded = np.load('data_combined.npz')\n",
    "    data_slices = loaded['data']\n",
    "    labels = loaded['labels']\n",
    "\n",
    "    # 創建LabelEncoder並進行編碼\n",
    "    label_encoder = LabelEncoder()\n",
    "    int_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "    # 保存LabelEncoder到.pkl文件\n",
    "    with open('Model/posture_label_encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(label_encoder, f)\n",
    "\n",
    "    # 打印標籤列表\n",
    "    print(f'Labels: {label_encoder.classes_}')\n",
    "\n",
    "    # 創建數據集和數據加載器\n",
    "    class SkeletonDataset(Dataset):\n",
    "        \"\"\"\n",
    "        自定義數據集類別，用於加載骨架數據。\n",
    "        \n",
    "        參數:\n",
    "        - data: numpy.ndarray，數據片段。\n",
    "        - labels: numpy.ndarray，數據標籤。\n",
    "        \"\"\"\n",
    "        def __init__(self, data, labels):\n",
    "            self.data = data\n",
    "            self.labels = labels\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "    train_dataset = SkeletonDataset(data_slices, int_labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    # 設置參數\n",
    "    input_dim = 33 * 4  # 33 keypoints * 4 coords (xyzv)\n",
    "    hidden_dim = 128\n",
    "    num_layers = 2\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    tcn_channels = [128, 128]\n",
    "\n",
    "    lstm_model = PostureLSTMModel(input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, num_classes=num_classes)\n",
    "    gru_model = PostureGRUModel(input_dim=input_dim, hidden_dim=hidden_dim, num_layers=num_layers, num_classes=num_classes)\n",
    "    tcn_model = PostureTemporalConvNet(num_inputs=input_dim, num_channels=tcn_channels, num_classes=num_classes, dropout=0.2)\n",
    "\n",
    "    # 創建集成模型\n",
    "    model = PostureEnsembleModel(lstm_model, gru_model, tcn_model, num_classes=num_classes)\n",
    "\n",
    "    # 將模型移動到GPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # 訓練函數\n",
    "    def train_model(model, train_loader, criterion, optimizer, num_epochs=20):\n",
    "        \"\"\"\n",
    "        訓練模型。\n",
    "        \n",
    "        參數:\n",
    "        - model: nn.Module，待訓練的模型。\n",
    "        - train_loader: DataLoader，訓練數據加載器。\n",
    "        - criterion: 損失函數。\n",
    "        - optimizer: 優化器。\n",
    "        - num_epochs: int，訓練的輪數。\n",
    "        \n",
    "        功能:\n",
    "        - 訓練模型並顯示訓練進度。\n",
    "        \"\"\"\n",
    "        progress = Progress(\n",
    "            SpinnerColumn(), \n",
    "            BarColumn(), \n",
    "            TextColumn(\"[progress.percentage]{task.percentage:>3.1f}%\"), \n",
    "            TextColumn(\"[progress.description]{task.description}\"),\n",
    "            auto_refresh=True\n",
    "        )\n",
    "\n",
    "        with Live(progress, refresh_per_second=10):\n",
    "            train_task = progress.add_task(\n",
    "                description=\"Initializing...\", \n",
    "                total=num_epochs * len(train_loader)\n",
    "            )\n",
    "            for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                running_loss = 0.0\n",
    "                \n",
    "                for inputs, labels in train_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    inputs = inputs.view(inputs.size(0), time_step, -1)  # 形狀為 (batch_size, frames, keypoints * coords)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "                    progress.update(\n",
    "                        train_task,\n",
    "                        description=f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\",\n",
    "                        advance=1\n",
    "                    )\n",
    "\n",
    "    # 評估函數\n",
    "    def evaluate_model(model, test_file_path):\n",
    "        \"\"\"\n",
    "        評估模型。\n",
    "        \n",
    "        參數:\n",
    "        - model: nn.Module，待評估的模型。\n",
    "        - test_file_path: str，測試數據的文件路徑。\n",
    "        \n",
    "        功能:\n",
    "        - 評估模型並顯示評估進度。\n",
    "        - 計算每一個動作的正確率。\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        action_correct = {}\n",
    "        action_total = {}\n",
    "\n",
    "        progress = Progress(\n",
    "            SpinnerColumn(), \n",
    "            BarColumn(), \n",
    "            TextColumn(\"[progress.percentage]{task.percentage:>3.1f}%\"), \n",
    "            TextColumn(\"[progress.description]{task.description}\"),\n",
    "            auto_refresh=True\n",
    "        )\n",
    "        \n",
    "        # 加載測試數據\n",
    "        loaded_test = np.load(test_file_path)\n",
    "        test_data_slices = loaded_test['data']\n",
    "        test_labels = loaded_test['labels']\n",
    "\n",
    "        # 創建測試數據集和數據加載器\n",
    "        test_dataset = SkeletonDataset(test_data_slices, label_encoder.transform(test_labels))\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        with Live(progress, refresh_per_second=10):\n",
    "            eval_task = progress.add_task(\"Evaluating\", total=len(test_loader))\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in test_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    inputs = inputs.view(1, time_step, -1)\n",
    "                    outputs = model(inputs)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    action = label_encoder.inverse_transform([labels.item()])[0]\n",
    "\n",
    "                    total_samples += 1\n",
    "                    if action not in action_total:\n",
    "                        action_total[action] = 0\n",
    "                        action_correct[action] = 0\n",
    "                    action_total[action] += 1\n",
    "                    if predicted.item() == labels.item():\n",
    "                        total_correct += 1\n",
    "                        action_correct[action] += 1\n",
    "\n",
    "                    progress.update(eval_task, advance=1)\n",
    "\n",
    "        overall_accuracy = 100 * total_correct / total_samples\n",
    "        print(f'Overall Accuracy of the model on the test set: {overall_accuracy:.2f}%')\n",
    "\n",
    "        for action in action_correct:\n",
    "            action_accuracy = 100 * action_correct[action] / action_total[action]\n",
    "            print(f'Accuracy for action {action}: {action_accuracy:.2f}%')\n",
    "\n",
    "    # 訓練模型\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs=128)\n",
    "\n",
    "    # 評估模型\n",
    "    evaluate_model(model, 'test_data.npz')\n",
    "\n",
    "    # 保存模型\n",
    "    torch.save({\n",
    "        'lstm_model_state_dict': lstm_model.state_dict(),\n",
    "        'gru_model_state_dict': gru_model.state_dict(),\n",
    "        'tcn_model_state_dict': tcn_model.state_dict(),\n",
    "        'ensemble_model_state_dict': model.state_dict()\n",
    "    }, r\"Model/Posture_ensemble_model.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Train the Posture Ensemble Model.\")\n",
    "    parser.add_argument(\"--time_step\", type=int, default=70, help=\"The size of the time step for the sliding window.\")\n",
    "    # 如果在 Jupyter Notebook 中運行，跳過 argparse\n",
    "    if \"ipykernel\" in sys.modules:\n",
    "        args = parser.parse_args([])\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "\n",
    "    main(args.time_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e074c-fa6e-48aa-85c3-7a6f10e60627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
