{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5d9503f-0a84-41b0-8c99-7c0748b9ee59",
   "metadata": {},
   "source": [
    "### 腳本結構\n",
    "\n",
    "```\n",
    "Train_main.py\n",
    "├── Update_action_npy.py\n",
    "├── Update_train.py\n",
    "├── Generate_training_data.py\n",
    "├── AugmentData.py\n",
    "└── TrainEnsembleModel.py\n",
    "```\n",
    "\n",
    "### 運行範例\n",
    "\n",
    "在命令行中運行這個腳本，您可以按照以下步驟進行：\n",
    "\n",
    "1. **打開命令行**：根據您的操作系統，打開命令行工具（如Windows的CMD、MacOS或Linux的終端）。\n",
    "\n",
    "2. **運行腳本**：\n",
    "\n",
    "    - 使用默認的 `time_step` 值（70）：\n",
    "\n",
    "        ```sh\n",
    "        python Train_main.py\n",
    "        ```\n",
    "\n",
    "    - 使用自定義的 `time_step` 值（例如 100）：\n",
    "\n",
    "        ```sh\n",
    "        python Train_main.py --time_step=100\n",
    "        ```\n",
    "\n",
    "### 運行示例解釋\n",
    "\n",
    "- 當您運行 `python Train_main.py` 時，腳本將按順序執行列表中的每個腳本。默認情況下，`time_step` 的值為 70。\n",
    "- 如果您指定了 `--time_step` 參數，腳本將使用您提供的值來運行需要 `time_step` 的腳本。例如，`python Train_main.py --time_step=100` 將使用 `time_step=100` 來運行 `Update_train.py` 和 `TrainEnsembleModel.py`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed874260-6b65-4923-98e3-d7fbe4ea1e26",
   "metadata": {},
   "source": [
    "# 大致流程\n",
    "\n",
    "### Update_action_npy.py\n",
    "- **功能**：處理指定目錄中的視頻文件，使用 MediaPipe Pose 模型提取每幀的骨架關鍵點資訊，並對這些關鍵點以髖部中心進行標準化處理後保存為 `.npy` 文件。僅在視頻文件比 `.npy` 文件更新時重新處理視頻，並顯示處理進度和每幀視頻的平均推理時間。\n",
    "\n",
    "### Update_train.py\n",
    "- **功能**：清空指定目錄，並將處理過的數據片段（骨架關鍵點資訊）進行滑動窗口處理，提取固定幀數的片段，保存為新的 `.npy` 文件。\n",
    "\n",
    "### Generate_training_data.py\n",
    "- **功能**：合併訓練資料夾中的數據片段，並保存為一個 `.npz` 文件，用於後續的訓練。打印各類別的數據片段數量。\n",
    "\n",
    "### AugmentData.py\n",
    "- **功能**：對數據進行水平翻轉增強，將原始數據和翻轉後的數據合併，並保存為新的 `.npz` 文件。打印合併後數據的每個標籤數量。\n",
    "\n",
    "### TrainEnsembleModel.py\n",
    "- **功能**：訓練和評估姿態集成模型。包括數據加載和標籤編碼，數據集分割，模型初始化，訓練和評估模型，最後保存訓練好的模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adee14c-51c6-4f3f-9cd4-f0a96dd94f21",
   "metadata": {},
   "source": [
    "# Update_action_npy.py\n",
    "\n",
    "這段程式碼的功能是遍歷指定目錄中的視頻文件，使用 MediaPipe Pose 模型提取每幀的骨架關鍵點資訊，並對這些關鍵點以髖部中心進行標準化處理後保存為 .npy 文件。如果目錄中已有相應的 .npy 文件，則僅在視頻文件比 .npy 文件更新時重新處理視頻。程式會生成進度條顯示處理進度，並最終計算和顯示每幀視頻的平均推理時間。這樣的處理有助於生成標準化的骨架數據，便於後續的姿態分析和機器學習模型訓練。\n",
    "\n",
    "\r\n",
    "1. **初始化**\r\n",
    "    - 初始化 MediaPipe Pose 模型，用於後續骨架關鍵點檢測。\r\n",
    "\r\n",
    "2. **定義路徑**\r\n",
    "    - 設置輸入目錄（`action`）和輸出目錄（`action_npy`）。\r\n",
    "    - 如果輸出目錄不存在，則創建該目錄。\r\n",
    "\r\n",
    "3. **處理視頻的 `process_video` 函數**\r\n",
    "    - 開啟視頻文件並初始化相關計時和數據變數。\r\n",
    "    - 循環讀取視頻的每幀：\r\n",
    "        - 計時讀取幀的時間。\r\n",
    "        - 將 BGR 圖像轉換為 RGB。\r\n",
    "        - 使用 MediaPipe Pose 模型進行姿態檢測。\r\n",
    "        - 計算推理時間並累積。\r\n",
    "        - 如果檢測到姿態，則提取關鍵點座標，並以左髖部和右髖部的中點為中心進行標準化。\r\n",
    "        - 保存標準化後的骨架關鍵點數據到 `frames_data`。\r\n",
    "    - 釋放視頻資源並將 `frames_data` 保存為 .npy 文件。\r\n",
    "    - 返回每幀的平均推理時間。\r\n",
    "\r\n",
    "4. **檢查視頻文件是否更新的 `is_new_file` 函數**\r\n",
    "    - 檢查 .npy 文件是否存在。\r\n",
    "    - 如果 .npy 文件存在，對比視頻文件和 .npy 文件的修改時間，判斷是否需要重新處理視頻文件。\r\n",
    "\r\n",
    "5. **主程序邏輯**\r\n",
    "    - 使用 `rich.progress` 顯示進度條。\r\n",
    "    - 遍歷輸入目錄中的每個子目錄（每個動作類別）：\r\n",
    "        - 對每個視頻文件，檢查相應的 .npy 文件是否需要更新。\r\n",
    "        - 如果需要更新，將視頻文件和輸出文件路徑添加到待處理任務列表中。\r\n",
    "    - 如果有待處理任務：\r\n",
    "        - 初始化進度條任務。\r\n",
    "        - 逐個處理待處理任務，對每個視頻文件調用 `process_video` 函數，並更新進度條。\r\n",
    "        - 計算並顯示所有視頻文件的平均關鍵點數據，並生成相應的 .npy 文件，便於後續的數據分析和機器學習應用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d631227e-e0c7-4d7b-8818-ee556e7d2ace",
   "metadata": {},
   "source": [
    "# Update_train.py\n",
    "\n",
    "### 1. 初始化與設定\n",
    "1. **設定資料夾路徑**\n",
    "    - 定義原始數據目錄 `npy_path` 為 `\"action_npy\"`。\n",
    "    - 定義輸出數據目錄 `train_path` 為 `\"train\"`。\n",
    "\n",
    "### 2. 定義與清空資料夾的函數\n",
    "2. **定義 `clear_directory` 函數**\n",
    "    - 檢查指定的目錄是否存在。\n",
    "    - 嘗試刪除該目錄及其內容。\n",
    "    - 如果遇到許可權問題，使用系統命令強制刪除目錄。\n",
    "    - 捕獲並打印其他可能的錯誤。\n",
    "\n",
    "### 3. 定義滑動窗口函數\n",
    "3. **定義 `sliding_window` 函數**\n",
    "    - 接受數據 `data`、窗口大小 `window_size`、步長 `step_size` 和標籤 `label`。\n",
    "    - 計算數據的總幀數、關鍵點數和坐標數。\n",
    "    - 使用滑動窗口從數據中提取片段，每個片段包含 `window_size` 幀。\n",
    "    - 將每個片段及其標籤添加到結果列表 `slices` 中。\n",
    "    - 處理不足一個步長的剩餘片段，確保不漏掉數據。\n",
    "    - 返回提取的數據片段列表。\n",
    "\n",
    "### 4. 處理和儲存數據的函數\n",
    "4. **定義 `process_and_save_data` 函數**\n",
    "    - 接受原始數據目錄 `npy_path`、保存處理後數據的目錄 `train_path`、窗口大小 `window_size` 和步長 `step_size`。\n",
    "    - 獲取所有動作類別（子目錄）的名稱。\n",
    "    - 對每個動作類別，檢查並創建對應的保存目錄。\n",
    "    - 遍歷每個動作類別下的所有 `.npy` 文件：\n",
    "        - 加載數據文件。\n",
    "        - 使用滑動窗口提取數據片段。\n",
    "        - 將提取的片段保存為新的 `.npy` 文件，文件名中包含片段的索引。\n",
    "\n",
    "### 5. 主程序邏輯\n",
    "5. **主程序執行邏輯**\n",
    "    - 使用 `argparse` 解析命令行參數，獲取滑動窗口大小 `time_step`。\n",
    "    - 調用 `clear_directory` 函數清空 `train` 目錄。\n",
    "    - 調用 `process_and_save_data` 函數處理原始數據，並將處理後的數據保存到 `train` 目錄。\n",
    "\n",
    "### 完整流程\n",
    "1. 初始化與設定資料夾路徑。\n",
    "2. 定義清空資料夾的 `clear_directory` 函數。\n",
    "3. 定義使用滑動窗口提取數據片段的 `sliding_window` 函數。\n",
    "4. 定義處理和保存數據的 `process_and_save_data` 函數。\n",
    "5. 在主程序中，解析命令行參數，清空 `train` 資料夾，並調用處理和保存數據的函數。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2757cb0a-eef3-4269-95e0-a540119787f5",
   "metadata": {},
   "source": [
    "# Generate_training_data.py\n",
    "當然，以下是這段程式碼的詳細流程條列說明：\n",
    "\n",
    "### 1. 初始化與設定\n",
    "1. **設定訓練資料夾路徑**\n",
    "    - 定義訓練數據目錄 `train_path` 為 `\"train\"`。\n",
    "\n",
    "### 2. 定義數據合併函數\n",
    "2. **定義 `combine_data` 函數**\n",
    "    - **初始化數據和標籤列表**\n",
    "        - 初始化 `data_slices` 列表用於存儲數據片段。\n",
    "        - 初始化 `labels` 列表用於存儲標籤。\n",
    "    - **初始化標籤計數字典**\n",
    "        - 初始化 `label_counts` 字典用於計數各類別的數據片段數量。\n",
    "    - **讀取訓練資料夾中的所有子資料夾**\n",
    "        - 使用 `os.listdir(train_path)` 讀取 `train_path` 資料夾中的所有子資料夾名稱（每個子資料夾代表一個動作類別）。\n",
    "    - **遍歷每個子資料夾**\n",
    "        - 檢查子資料夾是否為目錄。\n",
    "        - 讀取子資料夾中的所有文件。\n",
    "        - **遍歷每個文件**\n",
    "            - 構建文件的完整路徑。\n",
    "            - 加載 `.npy` 文件中的數據。\n",
    "            - 將數據片段添加到 `data_slices` 列表中。\n",
    "            - 將對應的標籤添加到 `labels` 列表中。\n",
    "            - 更新 `label_counts` 字典中該類別的計數。\n",
    "    - **將數據和標籤轉換為 numpy 數組**\n",
    "        - 使用 `np.array(data_slices)` 將數據片段列表轉換為 numpy 數組。\n",
    "        - 使用 `np.array(labels)` 將標籤列表轉換為 numpy 數組。\n",
    "    - **保存數據和標籤到 `.npz` 文件**\n",
    "        - 使用 `np.savez('data_combined.npz', data=data_slices, labels=labels)` 將數據和標籤保存到 `.npz` 文件。\n",
    "    - **打印各類別的資料數量**\n",
    "        - 遍歷 `label_counts` 字典並打印每個類別的數據片段數量。\n",
    "        - 打印總的數據片段數量。\n",
    "\n",
    "### 3. 主程序邏輯\n",
    "3. **主程序執行邏輯**\n",
    "    - 檢查是否作為主程序運行。\n",
    "    - 調用 `combine_data` 函數執行數據合併並保存處理過的數據。\n",
    "\n",
    "### 總結流程\n",
    "1. 設定訓練資料夾路徑。\n",
    "2. 定義 `combine_data` 函數，詳細步驟如下：\n",
    "    - 初始化數據和標籤列表。\n",
    "    - 初始化標籤計數字典。\n",
    "    - 讀取訓練資料夾中的所有子資料夾。\n",
    "    - 遍歷每個子資料夾，檢查是否為目錄。\n",
    "    - 讀取子資料夾中的所有文件，遍歷每個文件。\n",
    "    - 加載 `.npy` 文件中的數據並更新列表和字典。\n",
    "    - 將數據和標籤轉換為 numpy 數組。\n",
    "    - 保存數據和標籤到 `.npz` 文件。\n",
    "    - 打印各類別的資料數量和總數量。\n",
    "3. 在主程序中調用 `combine_data` 函數，執行數據合併並保存處理過的數據。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8156103-3a8d-4188-967f-daf8ba07127b",
   "metadata": {},
   "source": [
    "# AugmentData.py\n",
    "以下是這段程式碼的條列流程說明：\n",
    "\n",
    "### 1. 定義水平翻轉函數\n",
    "1. **定義 `horizontal_flip` 函數**\n",
    "    - 接受一個骨架數據（`skeleton`）作為輸入。\n",
    "    - 複製骨架數據，創建翻轉後的骨架數據副本。\n",
    "    - 將所有 x 座標（假設在偶數索引位置）取負數，實現水平翻轉。\n",
    "    - 返回翻轉後的骨架數據。\n",
    "\n",
    "### 2. 讀取數據\n",
    "2. **讀取保存的數據**\n",
    "    - 使用 `np.load('data_combined.npz')` 讀取之前保存的 `.npz` 文件。\n",
    "    - 將數據片段提取到 `X` 中，將標籤提取到 `y` 中。\n",
    "\n",
    "### 3. 對數據進行水平翻轉\n",
    "3. **應用水平翻轉**\n",
    "    - 使用 `horizontal_flip` 函數對 `X` 中的每一幀數據應用水平翻轉。\n",
    "    - 將翻轉後的數據存儲到 `X_flipped` 中。\n",
    "    - 複製標籤 `y` 到 `y_flipped`，標籤保持不變。\n",
    "\n",
    "### 4. 合併原始數據和翻轉數據\n",
    "4. **合併數據**\n",
    "    - 使用 `np.concatenate` 將原始數據 `X` 和翻轉數據 `X_flipped` 合併。\n",
    "    - 使用 `np.concatenate` 將原始標籤 `y` 和翻轉標籤 `y_flipped` 合併。\n",
    "    - 合併後的數據存儲在 `X_combined` 中，合併後的標籤存儲在 `y_combined` 中。\n",
    "\n",
    "### 5. 保存處理後的數據\n",
    "5. **保存合併後的數據**\n",
    "    - 使用 `np.savez('data_combined.npz', data=X_combined, labels=y_combined)` 將合併後的數據和標籤保存到 `.npz` 文件中。\n",
    "\n",
    "### 6. 計算並打印各類別數量\n",
    "6. **計算和打印標籤的數量**\n",
    "    - 使用 `Counter` 計算每個標籤出現的次數。\n",
    "    - 打印每個標籤對應的數據片段數量。\n",
    "\n",
    "### 總結流程\n",
    "1. 定義水平翻轉函數 `horizontal_flip`，對骨架數據進行水平翻轉。\n",
    "2. 讀取保存的數據和標籤。\n",
    "3. 對每幀數據應用水平翻轉，並保持標籤不變。\n",
    "4. 合併原始數據和翻轉數據，以及對應的標籤。\n",
    "5. 保存合併後的數據和標籤到 `.npz` 文件中。\n",
    "6. 計算並打印合併後數據的每個標籤數量。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc197c4-7fda-45a3-8c96-d86a5527d46a",
   "metadata": {},
   "source": [
    "# TrainEnsembleModel.py\n",
    "### 1. 設定與導入\n",
    "1. **導入相關模組**\n",
    "    - `os`：操作系統相關功能。\n",
    "    - `numpy`：數值計算庫。\n",
    "    - `torch`：PyTorch深度學習框架。\n",
    "    - `torch.utils.data.Dataset, DataLoader`：PyTorch數據集和數據加載器。\n",
    "    - `sklearn.model_selection.train_test_split`：數據集分割函數。\n",
    "    - `sklearn.preprocessing.LabelEncoder`：標籤編碼器。\n",
    "    - `torch.optim`：優化器。\n",
    "    - `rich.progress`：進度條顯示工具。\n",
    "    - `pickle`：數據序列化和反序列化。\n",
    "    - `Posture_ensemble_model`：自定義模型類。\n",
    "    - `torch.nn`：PyTorch神經網絡模組。\n",
    "    - `argparse`：命令行參數解析器。\n",
    "\n",
    "### 2. 主函數 `main`\n",
    "2. **定義 `main` 函數**\n",
    "    - **加載數據**\n",
    "        - 從 `data_combined.npz` 文件中加載數據片段和標籤。\n",
    "    - **標籤編碼**\n",
    "        - 使用 `LabelEncoder` 將標籤轉換為整數表示。\n",
    "        - 保存 `LabelEncoder` 到 `Model/posture_label_encoder.pkl` 文件。\n",
    "        - 打印標籤列表。\n",
    "    - **數據集分割**\n",
    "        - 使用 `train_test_split` 將數據集分割為訓練集和測試集。\n",
    "    - **創建數據集和數據加載器**\n",
    "        - 定義 `SkeletonDataset` 類，用於加載數據片段和標籤。\n",
    "        - 創建訓練和測試數據集。\n",
    "        - 創建訓練和測試數據加載器。\n",
    "    - **初始化模型和參數**\n",
    "        - 設置輸入維度、隱藏層維度、層數、類別數和 TCN 通道數。\n",
    "        - 初始化 LSTM、GRU 和 TCN 模型。\n",
    "        - 創建集成模型。\n",
    "        - 將模型移動到 GPU（如果可用）。\n",
    "    - **訓練和評估模型**\n",
    "        - 定義 `train_model` 函數，用於訓練模型。\n",
    "        - 定義 `evaluate_model` 函數，用於評估模型。\n",
    "        - 訓練模型。\n",
    "        - 評估模型。\n",
    "    - **保存模型**\n",
    "        - 將訓練好的模型保存到 `Model/Posture_ensemble_model.pth` 文件。\n",
    "\n",
    "### 3. 定義數據集類 `SkeletonDataset`\n",
    "3. **定義 `SkeletonDataset` 類**\n",
    "    - 初始化數據和標籤。\n",
    "    - 返回數據集的長度。\n",
    "    - 返回指定索引處的數據和標籤。\n",
    "\n",
    "### 4. 訓練函數 `train_model`\n",
    "4. **定義 `train_model` 函數**\n",
    "    - 設置進度條。\n",
    "    - 進行訓練過程：\n",
    "        - 將模型設置為訓練模式。\n",
    "        - 遍歷訓練數據加載器，進行前向傳播、計算損失、反向傳播和優化。\n",
    "        - 更新進度條顯示訓練過程中的損失值和進度。\n",
    "\n",
    "### 5. 評估函數 `evaluate_model`\n",
    "5. **定義 `evaluate_model` 函數**\n",
    "    - 設置進度條。\n",
    "    - 進行評估過程：\n",
    "        - 將模型設置為評估模式。\n",
    "        - 遍歷測試數據加載器，進行前向傳播，計算準確率，並更新進度條顯示評估過程中的進度。\n",
    "    - 打印模型在測試集上的準確率。\n",
    "\n",
    "### 6. 主程序邏輯\n",
    "6. **主程序執行邏輯**\n",
    "    - 使用 `argparse` 解析命令行參數，設置滑動窗口的大小（`time_step`）。\n",
    "    - 調用 `main` 函數，執行訓練和評估過程。\n",
    "\n",
    "### 總結流程\n",
    "1. 導入相關模組。\n",
    "2. 定義主函數 `main`：\n",
    "    - 加載數據並進行標籤編碼。\n",
    "    - 分割數據集為訓練集和測試集。\n",
    "    - 創建數據集和數據加載器。\n",
    "    - 初始化模型和參數。\n",
    "    - 訓練和評估模型。\n",
    "    - 保存模型。\n",
    "3. 定義數據集類 `SkeletonDataset`。\n",
    "4. 定義訓練函數 `train_model`。\n",
    "5. 定義評估函數 `evaluate_model`。\n",
    "6. 使用 `argparse` 解析命令行參數，設置滑動窗口大小，並調用 `main` 函數。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
